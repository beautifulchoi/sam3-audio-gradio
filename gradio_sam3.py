import subprocess
import time
import gc
from pathlib import Path
from typing import List, Tuple

import cv2
import gradio as gr
import numpy as np
import torch

from utils.get_youtube import download_youtube


def _path_from_uploaded(uploaded_file):
    """Robustly extract a local file path from Gradio upload variants."""
    if uploaded_file is None:
        return None
    # Gradio can pass a list/tuple of paths or file dicts
    if isinstance(uploaded_file, (list, tuple)) and uploaded_file:
        return _path_from_uploaded(uploaded_file[0])
    # Direct string path
    if isinstance(uploaded_file, (str, Path)):
        return str(uploaded_file)
    # Dict with name/path keys
    if isinstance(uploaded_file, dict):
        for key in ("path", "name", "tempfile", "data"):
            if key in uploaded_file and uploaded_file[key]:
                val = uploaded_file[key]
                if isinstance(val, (str, Path)):
                    return str(val)
        return None
    # File-like object
    if hasattr(uploaded_file, "name"):
        return str(uploaded_file.name)
    return None

DOWNLOAD_DIR = Path("downloads")
OUTPUT_DIR = Path("outputs")
DOWNLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)


def _resolve_video_path(uploaded_file, youtube_url: str) -> str:
    """Pick uploaded file first; otherwise download from YouTube."""
    path = _path_from_uploaded(uploaded_file)
    if path:
        return str(path)

    if youtube_url and youtube_url.strip():
        downloads = download_youtube(youtube_url.strip(), str(DOWNLOAD_DIR))
        return downloads["video_only"]

    raise ValueError("ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”.")


def _extract_first_frame(video_path: str) -> np.ndarray:
    cap = cv2.VideoCapture(video_path)
    ok, frame = cap.read()
    cap.release()
    if not ok or frame is None:
        raise RuntimeError(f"ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)


def _format_points(points: List[Tuple[float, float]]) -> str:
    if not points:
        return "í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    return "\n".join([f"{idx + 1}. ({int(x)}, {int(y)})" for idx, (x, y) in enumerate(points)])


def _draw_points_on_frame(frame: np.ndarray, points: List[Tuple[float, float]]):
    if frame is None:
        return None
    vis = frame.copy()
    for x, y in points:
        cv2.circle(vis, (int(x), int(y)), radius=4, color=(255, 0, 0), thickness=-1)  # red dot
    return vis


def load_video(video_file, youtube_url):
    """Load/upload/download video, grab first frame for point selection."""
    try:
        video_path = _resolve_video_path(video_file, youtube_url)
        # Normalize/ensure playable (H.264/yuv420p, limited size) for browser playback

        video_path = str(Path(video_path).resolve())
        if not Path(video_path).exists():
            raise RuntimeError(f"ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_path}")

        frame = _extract_first_frame(video_path)
        h, w = frame.shape[:2]
        msg = f"âœ… ë¹„ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ: {video_path} (w={w}, h={h})\ní¬ì¸íŠ¸ ëª¨ë“œëŠ” í”„ë ˆì„ì„ í´ë¦­í•´ ì¢Œí‘œë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
        return frame, video_path, [], (h, w), video_path, msg, _format_points([]), frame
    except Exception as e:
        return None, None, [], None, None, f"âŒ ë¹„ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}", _format_points([]), None


def record_point(evt: gr.SelectData, points: List[Tuple[float, float]], frame_hw: Tuple[int, int] | None, frame_image: np.ndarray | None):
    """Append clicked point (x,y) in pixel space and draw a red dot."""
    if frame_hw is None or frame_image is None:
        return points, _format_points(points), "âŒ ë¹„ë””ì˜¤ë¥¼ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ì„¸ìš”.", frame_image

    x, y = (evt.index or (None, None))
    if x is None or y is None:
        return points, _format_points(points), "âŒ ì¢Œí‘œë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í´ë¦­í•˜ì„¸ìš”.", frame_image

    new_points = points + [(float(x), float(y))]
    vis = _draw_points_on_frame(frame_image, new_points)
    return new_points, _format_points(new_points), f"ğŸ“ í¬ì¸íŠ¸ ì¶”ê°€: ({int(x)}, {int(y)})", vis


def clear_points(frame_image: np.ndarray | None):
    return [], _format_points([]), "ğŸ§¹ í¬ì¸íŠ¸ë¥¼ ëª¨ë‘ ì§€ì› ìŠµë‹ˆë‹¤.", frame_image


def run_sam(video_path: str | None, prompt_type: str, text_prompt: str, points: List[Tuple[float, float]]):
    if not video_path:
        return None, "âŒ ë¹„ë””ì˜¤ë¥¼ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ì„¸ìš”."

    ts = int(time.time())
    save_path = OUTPUT_DIR / f"sam3_mask_{prompt_type}_{ts}.mp4"

    try:
        if prompt_type == "text":
            if not text_prompt.strip():
                raise ValueError("í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            from get_mask_text import get_mask_from_text
            get_mask_from_text(video_path, prompt=text_prompt.strip(), save_path=str(save_path))
            msg = f"âœ… í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì™„ë£Œ. ê²°ê³¼ ì €ì¥: {save_path}"
        else:
            if not points:
                raise ValueError("í¬ì¸íŠ¸ë¥¼ í•œ ê°œ ì´ìƒ ì¶”ê°€í•˜ì„¸ìš”.")
            from get_mask_point import get_mask_from_point
            get_mask_from_point(video_path, point_prompt=points, save_path=str(save_path))
            msg = f"âœ… í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ ì™„ë£Œ. ê²°ê³¼ ì €ì¥: {save_path}"
    except Exception as e:
        raise e
        return None, f"âŒ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}"

    return str(save_path), msg


def clear_sam_memory():
    try:
        from get_mask_text import clear_sam as clear_text
        from get_mask_point import clear_sam_point
        cleared_text = bool(clear_text())
        cleared_point = bool(clear_sam_point())
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        gc.collect()
        status = "âœ… SAM ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ" if (cleared_text or cleared_point) else "âš ï¸ ì •ë¦¬í•  ë©”ëª¨ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤"
    except Exception as e:
        return f"âŒ SAM ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}"
    return status


def build_ui():
    with gr.Blocks() as demo:
        gr.Markdown("### SAM3 Video Masking\në¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ YouTube URLì„ ì…ë ¥í•œ ë’¤ í”„ë¡¬í”„íŠ¸ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”. í¬ì¸íŠ¸ ëª¨ë“œì—ì„œëŠ” ì²« í”„ë ˆì„ì„ í´ë¦­í•´ ì¢Œí‘œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")

        video_path_state = gr.State(value=None)
        points_state = gr.State(value=[])
        frame_hw_state = gr.State(value=None)
        frame_image_state = gr.State(value=None)

        with gr.Row():
            with gr.Column(scale=1):
                video_file = gr.Video(
                    label="ë¹„ë””ì˜¤ ì—…ë¡œë“œ (MP4)",
                    sources=["upload"],
                )
                youtube_url = gr.Textbox(label="YouTube URL (ì„ íƒ)", placeholder="https://www.youtube.com/...")
                load_btn = gr.Button("ë¹„ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° / ë‹¤ìš´ë¡œë“œ (ë¹„ë””ì˜¤ ì—…ë¡œë“œ í›„ í´ë¦­í•˜ì„¸ìš”)", variant="secondary")
                load_status = gr.Markdown("ë¹„ë””ì˜¤ë¥¼ ë¶ˆëŸ¬ì™€ ì²« í”„ë ˆì„ì„ í™•ì¸í•˜ì„¸ìš”.")

                prompt_type = gr.Radio(
                    ["text", "point"],
                    value="text",
                    label="í”„ë¡¬í”„íŠ¸ íƒ€ì…",
                )
                text_prompt = gr.Textbox(label="í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸", placeholder="ì˜ˆ: person", visible=True)

                point_frame = gr.Image(
                    label="í”„ë ˆì„ì—ì„œ í¬ì¸íŠ¸ í´ë¦­ (ì²« í”„ë ˆì„)",
                    type="numpy",
                    interactive=True,
                    visible=False,
                )
                points_display = gr.Markdown(_format_points([]), visible=False)
                clear_points_btn = gr.Button("í¬ì¸íŠ¸ ì§€ìš°ê¸°", variant="secondary", visible=False)
                clear_sam_btn = gr.Button("SAM ë©”ëª¨ë¦¬ ë¹„ìš°ê¸°", variant="secondary")

                submit_btn = gr.Button("Submit", variant="primary")
            with gr.Column(scale=1):
                result_video = gr.Video(label="ë§ˆìŠ¤í¬ ê²°ê³¼", interactive=False)
                status = gr.Markdown(label="ìƒíƒœ")

        # Toggle UI for text/point prompts
        prompt_type.change(
            lambda t: (
                gr.update(visible=t == "text"),
                gr.update(visible=t == "point"),
                gr.update(visible=t == "point"),
                gr.update(visible=t == "point"),
            ),
            inputs=prompt_type,
            outputs=[text_prompt, point_frame, points_display, clear_points_btn],
        )

        # Load video (upload or YouTube) and extract first frame
        load_btn.click(
            load_video,
            inputs=[video_file, youtube_url],
            outputs=[
                point_frame,
                video_path_state,
                points_state,
                frame_hw_state,
                result_video,
                load_status,
                points_display,
                frame_image_state,
            ],
        )

        # Capture point clicks on the frame
        point_frame.select(
            record_point,
            inputs=[points_state, frame_hw_state, frame_image_state],
            outputs=[points_state, points_display, status, point_frame],
        )

        clear_points_btn.click(
            clear_points,
            inputs=[frame_image_state],
            outputs=[points_state, points_display, status, point_frame],
        )

        clear_sam_btn.click(
            clear_sam_memory,
            inputs=[],
            outputs=[status],
        )

        submit_btn.click(
            run_sam,
            inputs=[video_path_state, prompt_type, text_prompt, points_state],
            outputs=[result_video, status],
        )
    return demo


if __name__ == "__main__":
    demo = build_ui()
    demo.launch()
